{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d04c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5f83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(\"/Social Network Analysis/gephi_export.csv\", sep=\",\");\n",
    "df_nodes = pd.read_csv(\"/Social Network Analysis/gephi_export_nodes.csv\", sep=\",\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_cols = list(df_nodes.columns.to_list());\n",
    "edges_cols = list(df_edges.columns.to_list());\n",
    "nodes_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ec11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clusters(nodelist):\n",
    "    cluster_list = list();\n",
    "    while(len(nodelist) > 0):\n",
    "        new_cluster = list();\n",
    "        new_cluster.append(nodelist.pop(0));\n",
    "        all_checked = False;\n",
    "        while(not all_checked):\n",
    "            all_checked = True;\n",
    "            for potential_node in nodelist:\n",
    "                #print(f\"pot {potential_node}, clust {new_cluster[-1]} : \\r\\n -------------------------------------------\")\n",
    "                for i in range(0,len(df_edges)):\n",
    "                    #print(f\"Source {df_edges.iloc[i].Source}, Target {df_edges.iloc[i].Source}\")\n",
    "                    if(((df_edges.iloc[i].Source == potential_node) and (df_edges.iloc[i].Target in new_cluster)) or\n",
    "       ((df_edges.iloc[i].Source in new_cluster) and (df_edges.iloc[i].Target == potential_node))):\n",
    "                        new_cluster.append(potential_node);\n",
    "                        nodelist.remove(potential_node);\n",
    "                        all_checked = False;\n",
    "                        #print(\"true\")\n",
    "                        break;\n",
    "        cluster_list.append(new_cluster);\n",
    "    return cluster_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8f9962",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "communities = df_nodes[\"community\"].drop_duplicates().to_list();\n",
    "graph = {};\n",
    "\n",
    "for c in communities:\n",
    "    b = df_nodes.loc[df_nodes[\"community\"] == c, 'Id'].to_list();\n",
    "    graph[c] = make_clusters(b);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a806ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame();\n",
    "df_corr.assign(Male=[0], Female=[0], Organization=[0])\n",
    "gender = ['Male','Female','Organization']\n",
    "for i in range(0,3):\n",
    "    for i2 in range(0,3):\n",
    "        df_corr.loc[i,i2] = round(len(df_edges.loc[\n",
    "            df_edges[\"Source\"].isin(df_nodes.loc[df_nodes[\"gender\"] == gender[i],\"Id\"])\n",
    "            & df_edges[\"Target\"].isin(df_nodes.loc[df_nodes[\"gender\"] == gender[i2],\"Id\"])\n",
    "        ]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fb6927e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.1</td>\n",
       "      <td>53.1</td>\n",
       "      <td>28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2\n",
       "0  56.1  32.9  31.6\n",
       "1  30.1  53.1  28.9\n",
       "2  13.8  14.1  39.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2852eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in gender:\n",
    "    print(i)\n",
    "    print(df_nodes.loc[df_nodes[\"gender\"] == i, \"Betweenness Centrality\"].mean())\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.set_title(f\"Verteilung der Betweenness Centrality\", fontsize=13)\n",
    "ax.set_ylabel(\"Betweenness Centrality\", fontsize=13)\n",
    "ax.set_xlabel(\"index\");\n",
    "ax.scatter(range(0,len(df_nodes.loc[df_nodes[\"gender\"] == \"Male\"])), df_nodes.loc[df_nodes[\"gender\"] == \"Male\",\"Betweenness Centrality\"], color=\"blue\", label=\"Male\")\n",
    "\n",
    "ax.scatter(range(0,len(df_nodes.loc[df_nodes[\"gender\"] == \"Female\"])), df_nodes.loc[df_nodes[\"gender\"] == \"Female\",\"Betweenness Centrality\"], color=\"pink\", label=\"Female\")\n",
    "\n",
    "ax.scatter(range(0,len(df_nodes.loc[df_nodes[\"gender\"] == \"Organization\"])), df_nodes.loc[df_nodes[\"gender\"] == \"Organization\",\"Betweenness Centrality\"], color=\"orange\", label=\"Organization\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cfe6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "img = ax.imshow(df_corr, cmap=\"Blues\", interpolation=\"nearest\", vmin=0, vmax=100)\n",
    "plt.colorbar(img, shrink=0.7)\n",
    "\n",
    "for i in range(df_corr.shape[0]):\n",
    "    for j in range(df_corr.shape[1]):\n",
    "        ax.text(j, i, f'{df_corr.iloc[i, j]:.1f}', ha=\"center\", va=\"center\", color=\"black\", fontsize=20)\n",
    "\n",
    "ax.set_ylabel(\"Ausgehend\", fontsize = 13)\n",
    "ax.set_xlabel(\"Eingehend\", fontsize = 13)\n",
    "ax.set_xticks(np.arange(len(df_corr.columns)), ['Male','Female','Org'], rotation=90, fontsize = 16)\n",
    "ax.set_yticks(np.arange(len(df_corr.columns)), ['Male','Female','Org'], fontsize = 16)\n",
    "ax.set_title(\"Eingehende Kanten prozentual und auf eine Stelle gerundet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d697f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node_dfs = {};\n",
    "for c in communities:\n",
    "    for i in range(0,len(graph[c])):\n",
    "        s = f\"{c}{i}\"\n",
    "        if(len(graph[c][i]) == 1):\n",
    "            s = graph[c][i][0];\n",
    "        new_node_dfs[s] = df_nodes.loc[df_nodes[\"Id\"].isin(graph[c][i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3377a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_edges = pd.DataFrame();\n",
    "df_new_nodes = pd.DataFrame();\n",
    "\n",
    "for s in ['Source', 'Target', 'Mutuality', 'Weight']:\n",
    "    df_new_edges[s] = None;\n",
    "\n",
    "node_attributes = ['Node_Id', 'community', 'Anz_Knoten', 'Anteil_Mutual_edges', 'In/Out_verhältnis', 'Anteil Männlich', 'AVG_inner_Closness_Centrality']\n",
    "single_node_atts = ['in-Degree',\n",
    " 'Excentricity',\n",
    " 'Closness Centrality',\n",
    " 'Harmonic Closness Centrality',\n",
    " 'Betweenness Centrality',\n",
    " 'Eigenvector Centrality',\n",
    " 'Clustering Coefficient']\n",
    "\n",
    "for s in single_node_atts:\n",
    "    node_attributes.append(f\"AVG_{s}\")\n",
    "    node_attributes.append(f\"SIGMA_{s}\")\n",
    "    \n",
    "for s in node_attributes:\n",
    "    df_new_nodes[s] = None;\n",
    "\n",
    "node_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c6560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in list(new_node_dfs.keys()):\n",
    "    \n",
    "    node_id = key;\n",
    "    \n",
    "    male_ratio = len(new_node_dfs[key].loc[new_node_dfs[key][\"gender\"] == \"Male\"]) / len(new_node_dfs[key].loc[ new_node_dfs[key][\"gender\"].isin([\"Male\", \"Female\"])])\n",
    "    \n",
    "    community = new_node_dfs[key].iloc[0][\"community\"]\n",
    "    \n",
    "    Anz_Knoten = len(new_node_dfs[key])\n",
    "    \n",
    "    df_temp = df_edges.loc[df_edges[\"Source\"].isin(new_node_dfs[key][\"Id\"].to_list()) \n",
    "                          |\n",
    "                       df_edges[\"Target\"].isin(new_node_dfs[key][\"Id\"].to_list())\n",
    "                      ]\n",
    "    \n",
    "    df_temp['pair'] = df_temp.apply(lambda row: tuple(sorted([row['Source'], row['Target']])), axis=1)\n",
    "    mutual_edges = df_temp[df_temp.duplicated('pair', keep = False)].drop(columns=['pair'])\n",
    "    \n",
    "    Anteil_Mutual_edges = len(mutual_edges) / len(df_temp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Out_verhältnis = len(\n",
    "        df_edges.loc[\n",
    "            df_edges[\"Source\"].isin(new_node_dfs[key][\"Id\"].to_list())\n",
    "            & ~ df_edges[\"Target\"].isin(new_node_dfs[key][\"Id\"].to_list())\n",
    "        ]) / len(df_edges.loc[df_edges[\"Source\"].isin(new_node_dfs[key][\"Id\"].to_list())])\n",
    "    \n",
    "    \n",
    "    G = nx.from_pandas_edgelist(df_temp, source='Source', target='Target', create_using=nx.DiGraph())\n",
    "    \n",
    "    inner_closness = list();\n",
    "    for i in range(0,len(new_node_dfs[key])):\n",
    "        path_length_sum = 0\n",
    "        number_of_paths = 0\n",
    "        for j in range(0,len(new_node_dfs[key])):\n",
    "            try:\n",
    "                shortest_path = nx.shortest_path(G, source=new_node_dfs[key].iloc[i][\"Id\"], target=new_node_dfs[key].iloc[j][\"Id\"])\n",
    "                number_of_paths = number_of_paths + 1\n",
    "                path_length_sum += len(shortest_path)\n",
    "            except Exception as e :\n",
    "                a = 0\n",
    "        if (path_length_sum > 0):\n",
    "            inner_closness.append(number_of_paths / path_length_sum)\n",
    "        else:\n",
    "            inner_closness.append(0)\n",
    "    \n",
    "    \n",
    "    AVG_inner_Closness_Centrality = 0\n",
    "    for d in inner_closness:\n",
    "        AVG_inner_Closness_Centrality += d\n",
    "    AVG_inner_Closness_Centrality = AVG_inner_Closness_Centrality / len(inner_closness)\n",
    "    \n",
    "    \n",
    "    \n",
    "    AVG_in_Degree = new_node_dfs[key][\"in-Degree\"].mean()\n",
    "    SIGMA_in_Degree = new_node_dfs[key][\"in-Degree\"].std()\n",
    "    AVG_Excentricity = new_node_dfs[key][\"Excentricity\"].mean()\n",
    "    SIGMA_Excentricity = new_node_dfs[key][\"Excentricity\"].std()\n",
    "    AVG_Closness_Centrality = new_node_dfs[key][\"Closness Centrality\"].mean()\n",
    "    SIGMA_Closness_Centrality = new_node_dfs[key][\"Closness Centrality\"].std()\n",
    "    AVG_Harmonic_Closness_Centrality = new_node_dfs[key][\"Harmonic Closness Centrality\"].mean()\n",
    "    SIGMA_Harmonic_Closness_Centrality = new_node_dfs[key][\"Harmonic Closness Centrality\"].std()\n",
    "    AVG_Betweenness_Centrality = new_node_dfs[key][\"Betweenness Centrality\"].mean()\n",
    "    SIGMA_Betweenness_Centrality = new_node_dfs[key][\"Betweenness Centrality\"].std()\n",
    "    AVG_Eigenvector_Centrality = new_node_dfs[key][\"Eigenvector Centrality\"].mean()\n",
    "    SIGMA_Eigenvector_Centrality = new_node_dfs[key][\"Eigenvector Centrality\"].std()\n",
    "    AVG_Clustering_Coefficient = new_node_dfs[key][\"Clustering Coefficient\"].mean()\n",
    "    SIGMA_Clustering_Coefficient = new_node_dfs[key][\"Clustering Coefficient\"].std()\n",
    "    \n",
    "    new_entry = {\n",
    "    'Node_Id': node_id,\n",
    "    'community': community,\n",
    "    'Anz_Knoten': Anz_Knoten,\n",
    "    'Anteil_Mutual_edges': Anteil_Mutual_edges,\n",
    "    'In/Out_verhältnis': Out_verhältnis,\n",
    "    'Anteil Männlich' : male_ratio,\n",
    "    'AVG_inner_Closness_Centrality': AVG_inner_Closness_Centrality,\n",
    "    'AVG_in-Degree': AVG_in_Degree,\n",
    "    'SIGMA_in-Degree': SIGMA_in_Degree,\n",
    "    'AVG_Excentricity': AVG_Excentricity,\n",
    "    'SIGMA_Excentricity': SIGMA_Excentricity,\n",
    "    'AVG_Closness Centrality': AVG_Closness_Centrality,\n",
    "    'SIGMA_Closness Centrality': SIGMA_Closness_Centrality,\n",
    "    'AVG_Harmonic Closness Centrality': AVG_Harmonic_Closness_Centrality,\n",
    "    'SIGMA_Harmonic Closness Centrality': SIGMA_Harmonic_Closness_Centrality,\n",
    "    'AVG_Betweenness Centrality': AVG_Betweenness_Centrality,\n",
    "    'SIGMA_Betweenness Centrality': SIGMA_Betweenness_Centrality,\n",
    "    'AVG_Eigenvector Centrality': AVG_Eigenvector_Centrality,\n",
    "    'SIGMA_Eigenvector Centrality': SIGMA_Eigenvector_Centrality,\n",
    "    'AVG_Clustering Coefficient': AVG_Clustering_Coefficient,\n",
    "    'SIGMA_Clustering Coefficient': SIGMA_Clustering_Coefficient\n",
    "    }\n",
    "\n",
    "    df_new_nodes = df_new_nodes.append(new_entry, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c46f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_key in list(new_node_dfs.keys()):\n",
    "    for target_key in list(new_node_dfs.keys()):\n",
    "        if (source_key == target_key):\n",
    "            continue;\n",
    "        \n",
    "        weight = len(df_edges.loc[df_edges[\"Source\"].isin(new_node_dfs[source_key][\"Id\"]) & df_edges[\"Target\"].isin(new_node_dfs[target_key][\"Id\"])])\n",
    "            \n",
    "        df_temp['pair'] = df_temp.apply(lambda row: tuple(sorted([row['Source'], row['Target']])), axis=1)\n",
    "        mutual_edges = df_temp[df_temp.duplicated('pair', keep = False)].drop(columns=['pair'])    \n",
    "            \n",
    "        if(weight == 0):\n",
    "            mutuality = 0;\n",
    "        else:    \n",
    "            mutuality = len(mutual_edges.loc[\n",
    "                mutual_edges[\"Source\"].isin(new_node_dfs[source_key][\"Id\"]) & mutual_edges[\"Target\"].isin(new_node_dfs[target_key][\"Id\"])\n",
    "            ]) / weight\n",
    "        \n",
    "        new_entry = {\n",
    "            'Source': source_key,\n",
    "            'Target': target_key,\n",
    "            'Mutuality' : mutuality,\n",
    "            'Weight' : weight\n",
    "        }\n",
    "        print(new_entry)\n",
    "        if(weight > 0):\n",
    "            df_new_edges = df_new_edges.append(new_entry, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ba9812",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new_nodes.to_csv('new_nodes.csv', sep='\\t', index=False)\n",
    "df_new_edges.to_csv('new_edges.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
